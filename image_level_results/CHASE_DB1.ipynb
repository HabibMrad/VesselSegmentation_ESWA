{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Imports **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from file_io import load as load_image\n",
    "from joblib import load\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Auxiliary Function **\n",
    "\n",
    "_ Inputs_\n",
    "\n",
    "* __pred -__ the  binary segmentation;\n",
    "* __gt -__ the ground truth; \n",
    "* __mask -__ the binary mask; \n",
    "* __ prob -__ the probability map.\n",
    "\n",
    "_ Outputs _\n",
    "\n",
    "* __sen -__ Sensibility;\n",
    "* __spec -__ Specificity; \n",
    "* __acc -__ Accuracy; \n",
    "* __ auc -__ Area Under the ROC curve;\n",
    "* __ mcc -__ Matthews Correlation Coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, matthews_corrcoef\n",
    "\n",
    "def perform_metrics (pred, gt, mask, prob):\n",
    "    \n",
    "    # Suppressing background regions.\n",
    "    pred = pred[mask>0]\n",
    "    gt = gt[mask>0]\n",
    "    prob = prob[mask>0]\n",
    "\n",
    "    # Building confusion matrix.\n",
    "    c_matrix = confusion_matrix(gt, pred)\n",
    "    \n",
    "    # Calculating ratios.\n",
    "    tn = c_matrix[0,0]\n",
    "    tp = c_matrix[1,1]\n",
    "    fn = c_matrix[1,0]\n",
    "    fp = c_matrix[0,1]\n",
    "    \n",
    "    # Finding the metrics.\n",
    "    sen  = tp/(tp + fn)\n",
    "    spec = tn/(tn + fp)\n",
    "    acc  = (tp + tn)/(tp + tn + fp + fn)\n",
    "    auc  = roc_auc_score (gt, prob)\n",
    "    mcc  = matthews_corrcoef (gt, pred)\n",
    "    \n",
    "    \n",
    "    return sen, spec, acc, auc, mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Loading **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = ['01R', '01L', '02R', '02L', '03R', '03L', '04R', '04L', '05R', '05L', '06R', '06L', '07R', '07L', '08R', '08L', '09R', '09L', '10R', '10L', '11R', '11L', '12R', '12L', '13R', '13L', '14R', '14L']\n",
    "r_width, r_height = 999, 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gts = np.zeros((len(test_images), r_height, r_width))\n",
    "masks = np.zeros ((len(test_images), r_height, r_width))\n",
    "segs = np.zeros((len(test_images), r_height, r_width))\n",
    "probs = np.zeros((len(test_images), r_height, r_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, image in enumerate(test_images):\n",
    "    gt = load_image('../resources/gts/CHASE_DB1/Image_%s_1stHO.png' %image, normalize = True)\n",
    "    mask = load_image('../resources/masks/CHASE_DB1/mask_%s.png' %image)\n",
    "    seg = load_image('../resources/binary_segmentations/CHASE_DB1/seg_0%s.png' %image, normalize = True)\n",
    "    prob = load('../resources/probability_maps/CHASE_DB1/prob_0%s.npy' %image)[1]\n",
    "    \n",
    "    gts[i] = gt\n",
    "    masks [i] = mask\n",
    "    segs[i] = seg\n",
    "    probs[i] = prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Calculating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sen_list, spec_list, acc_list, auc_list, mcc_list = [], [], [], [], []\n",
    "\n",
    "for i in range (len(gts)):\n",
    "    sen, spec, acc, auc, mcc = perform_metrics (segs[i], gts[i], masks[i], probs[i])\n",
    "    sen_list.append(sen)\n",
    "    spec_list.append(spec)\n",
    "    acc_list.append(acc)\n",
    "    auc_list.append(auc)\n",
    "    mcc_list.append(mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Storing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'Image' : test_images, 'Sensitivity': sen_list, 'Specificity': spec_list, \n",
    "        'Accuracy': acc_list, 'AUC': auc_list, 'MCC': mcc_list}\n",
    "\n",
    "df = pd.DataFrame(data = data)\n",
    "df = df[['Image', 'Sensitivity','Specificity','Accuracy', 'AUC', 'MCC']]\n",
    "df.set_index('Image', inplace = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Image-level results **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Average Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
